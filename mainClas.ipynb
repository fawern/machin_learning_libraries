{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import classification as cls_\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data = {\n",
    "    'Gelir': [50000, 60000, 30000, 80000, 40000, 55000, 62000, 48000, 70000, 75000, 42000, 68000, 55000, 62000, 40000, 58000, 67000, 43000, 71000, 55000, 60000, 40000, 65000, 72000, 45000, 59000, 68000, 36000, 69000, 70000],\n",
    "    'Kredi Puanı': [700, 750, 600, 800, 650, 720, 740, 710, 680, 720, 670, 750, 680, 730, 640, 760, 690, 710, 780, 720, 730, 650, 740, 760, 690, 720, 750, 670, 770, 780],\n",
    "    'Borç Oranı ': [0.2, 0.3, 0.5, 0.1, 0.4, 0.25, 0.15, 0.3, 0.4, 0.2, 0.35, 0.15, 0.3, 0.25, 0.45, 0.2, 0.35, 0.4, 0.2, 0.25, 0.3, 0.4, 0.35, 0.15, 0.2, 0.25, 0.3, 0.45, 0.15, 0.2],\n",
    "    'Kredi Durumu': ['Onaylandı', 'Onaylandı', 'Reddedildi', 'Onaylandı', 'Reddedildi', 'Onaylandı', 'Reddedildi', 'Onaylandı', 'Reddedildi', 'Onaylandı', 'Onaylandı', 'Reddedildi', 'Onaylandı', 'Onaylandı', 'Reddedildi', 'Onaylandı', 'Onaylandı', 'Reddedildi', 'Onaylandı', 'Onaylandı', 'Onaylandı', 'Reddedildi', 'Onaylandı', 'Onaylandı', 'Reddedildi', 'Onaylandı', 'Onaylandı', 'Onaylandı', 'Reddedildi', 'Reddedildi']\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "y = y.map({'Onaylandı': 1, 'Reddedildi': 0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "\n",
    "(\n",
    "    models_output_list,\n",
    "    highest_acs_output,\n",
    "    highest_f1s_output,\n",
    "    highest_prs_output,\n",
    "    highest_rcs_output,\n",
    "    highest_rocs_output,\n",
    ") = cls_.Classification.classification_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy 0.6666666666666666\n",
      "SVC accuracy 0.5\n",
      "Random Forest accuracy 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logreg_model = cls_.Classification(\n",
    "    model=LogisticRegression(), \n",
    "    train_data=X_train, test_data=X_test, \n",
    "    train_target=y_train, test_target=y_test\n",
    ")\n",
    "\n",
    "svc_model = cls_.Classification(\n",
    "    model=SVC(),\n",
    "    train_data=X_train, test_data=X_test,\n",
    "    train_target=y_train, test_target=y_test\n",
    ")\n",
    "rf_model = cls_.Classification(\n",
    "    model=RandomForestClassifier(),\n",
    "    train_data=X_train, test_data=X_test,\n",
    "    train_target=y_train, test_target=y_test\n",
    ")\n",
    "\n",
    "print('Logistic Regression accuracy', logreg_model.fit_predict())\n",
    "print('SVC accuracy', svc_model.fit_predict())\n",
    "print('Random Forest accuracy', rf_model.fit_predict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Models and Evaluation Results:\n",
      "\n",
      "Model with the Highest Accuracy:\n",
      "['RandomForestClassifier', 0.8333333333333334]\n",
      "\n",
      "Model with the Highest F1 Score:\n",
      "['RandomForestClassifier', 0.8571428571428571]\n",
      "\n",
      "Model with the Highest Precision:\n",
      "['KNeighborsClassifier', 1.0]\n",
      "\n",
      "Model with the Highest Recall:\n",
      "['LogisticRegression', 1.0]\n",
      "\n",
      "Model with the Highest ROC-AUC Score:\n",
      "['RandomForestClassifier', 0.8333333333333334]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Models and Evaluation Results:\")\n",
    "\n",
    "print(\"\\nModel with the Highest Accuracy:\")\n",
    "print(highest_acs_output)\n",
    "\n",
    "print(\"\\nModel with the Highest F1 Score:\")\n",
    "print(highest_f1s_output)\n",
    "\n",
    "print(\"\\nModel with the Highest Precision:\")\n",
    "print(highest_prs_output)\n",
    "\n",
    "print(\"\\nModel with the Highest Recall:\")\n",
    "print(highest_rcs_output)\n",
    "\n",
    "print(\"\\nModel with the Highest ROC-AUC Score:\")\n",
    "print(highest_rocs_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: ['accuracy_score', 0.6666666666666666, 'precision_score', 0.6, 'f1_score', 0.7499999999999999, 'recall_score', 1.0, 'roc_auc_score', 0.6666666666666667]\n",
      "KNeighborsClassifier: ['accuracy_score', 0.6666666666666666, 'precision_score', 1.0, 'f1_score', 0.5, 'recall_score', 0.3333333333333333, 'roc_auc_score', 0.6666666666666666]\n",
      "DecisionTreeClassifier: ['accuracy_score', 0.5, 'precision_score', 0.5, 'f1_score', 0.6666666666666666, 'recall_score', 1.0, 'roc_auc_score', 0.5]\n",
      "SVC: ['accuracy_score', 0.5, 'precision_score', 0.5, 'f1_score', 0.6666666666666666, 'recall_score', 1.0, 'roc_auc_score', 0.5]\n",
      "RandomForestClassifier: ['accuracy_score', 0.8333333333333334, 'precision_score', 0.75, 'f1_score', 0.8571428571428571, 'recall_score', 1.0, 'roc_auc_score', 0.8333333333333334]\n",
      "GradientBoostingClassifier: ['accuracy_score', 0.5, 'precision_score', 0.5, 'f1_score', 0.5714285714285715, 'recall_score', 0.6666666666666666, 'roc_auc_score', 0.5]\n",
      "XGBClassifier: ['accuracy_score', 0.6666666666666666, 'precision_score', 0.6, 'f1_score', 0.7499999999999999, 'recall_score', 1.0, 'roc_auc_score', 0.6666666666666667]\n",
      "XGBRFClassifier: ['accuracy_score', 0.6666666666666666, 'precision_score', 0.6, 'f1_score', 0.7499999999999999, 'recall_score', 1.0, 'roc_auc_score', 0.6666666666666667]\n",
      "LGBMClassifier: ['accuracy_score', 0.5, 'precision_score', 0.5, 'f1_score', 0.6666666666666666, 'recall_score', 1.0, 'roc_auc_score', 0.5]\n",
      "CatBoostClassifier: ['accuracy_score', 0.8333333333333334, 'precision_score', 0.75, 'f1_score', 0.8571428571428571, 'recall_score', 1.0, 'roc_auc_score', 0.8333333333333334]\n",
      "GaussianNB: ['accuracy_score', 0.6666666666666666, 'precision_score', 0.6666666666666666, 'f1_score', 0.6666666666666666, 'recall_score', 0.6666666666666666, 'roc_auc_score', 0.6666666666666667]\n",
      "MLPClassifier: ['accuracy_score', 0.5, 'precision_score', 0.5, 'f1_score', 0.6666666666666666, 'recall_score', 1.0, 'roc_auc_score', 0.5]\n"
     ]
    }
   ],
   "source": [
    "for model_output in models_output_list:\n",
    "    model_name = model_output[0]\n",
    "    evaluation_results = model_output[1]\n",
    "    print(f\"{model_name}: {evaluation_results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
